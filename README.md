# Web Scraping Seblak Products from E-commerce

_This project involves web scraping data related to Seblak products from an e-commerce platform. The collected data includes product names, prices, seller names, sales locations, total sales, and product ratings._

## Table of Contents

- [Introduction](#introduction)
- [Dataset](#dataset)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Usage](#usage)
- [Features](#features)
- [License](#license)
- [Contact](#contact)

## Introduction

This project demonstrates the use of web scraping techniques to gather data on Seblak products from an e-commerce platform. By automating the process of data collection, the project aims to analyze various aspects of Seblak products, such as pricing trends, sales performance, and customer ratings.

**Tools & Libraries Used:**
- Python
- BeautifulSoup
- Selenium
- pandas
- numpy
- matplotlib

This project is designed for data enthusiasts interested in web scraping and e-commerce data analysis.

## Dataset

The dataset is generated by scraping data from multiple pages on the e-commerce platform. The following information is extracted:

- **Product Names**
- **Prices**
- **Seller Names**
- **Sales Locations**
- **Total Sales**
- **Product Ratings**

## Project Structure

This project is organized as follows:

```plaintext
P0G3_Clara.ipynb - Jupyter notebook containing the web scraping and analysis code
README.md        - Project documentation
```

## Installation

To run the notebook, you will need the following:

- Python 3.x
- Jupyter Notebook
- Chrome WebDriver (compatible with your Chrome browser version)

It's recommended to use a virtual environment:

```bash
python -m venv env
source env/bin/activate  # On Windows use `env\Scripts\activate`
pip install -r requirements.txt
```

Install required libraries:

```bash
pip install beautifulsoup4 selenium pandas numpy matplotlib
```

## Usage

1. **Clone the repository**:

   ```bash
   git clone https://github.com/yourusername/your-repo-name.git
   ```

2. **Navigate to the project directory**:

   ```bash
   cd your-repo-name
   ```

3. **Download and set up Chrome WebDriver**:
   
   Ensure that the Chrome WebDriver is installed and accessible in your system's PATH. The WebDriver version should match your installed Chrome browser version.

4. **Open the Jupyter notebook**:

   ```bash
   jupyter notebook P0G3_Clara.ipynb
   ```

5. **Run the cells** to start the web scraping process. The notebook will automatically navigate through multiple pages of the e-commerce platform, scrape the relevant data, and store it in structured form for analysis.

## Features

- **Automated Data Collection**: Scraping product data from multiple pages of the e-commerce platform.
- **Data Analysis**: Analyzing pricing trends, sales distribution, and customer ratings of Seblak products.
- **Visualization**: Visualizing the collected data using matplotlib.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Contact

For questions, feedback, or contributions, contact:

- **Name**: Clara Putri Herlin
- **Email**: cputriherlin@gmail.com
- **LinkedIn**: [Clara Putri Herlin](https://www.linkedin.com/in/clara-putri-herlin)
  
